"""Thin wrappers for normalizing threat intelligence data from several Threat Intelligence sources into a common schema.

This module supports normalization for VirusTotal, AbuseIPDB, ipinfo.io, AlienVault OTX, urlscan.io threat intelligence data.
"""

from datetime import datetime, timezone
from helper_functions.logging_config import setup_logger

logger = setup_logger(name="normalize_threat_intelligence", log_file="that-socs.log")


# TODO: Fine tune schema as needed
class ThreatIntelligenceNormalizedSchema:
    """Common schema for normalized threat intelligence data.

    Attributes:
        # Metadata
        schema_version (str): Version of the normalization schema. Added for future backwards compatibility considerations.
        normalized_time (str): ISO 8601 timestamp when normalization was performed.

        # Core IOC Information
        source (str): Source of the threat intelligence data (e.g., 'VirusTotal', 'AbuseIPDB', 'ipinfo.io')
        ioc_type (str): Type of IOC ('ip', 'file_hash', 'domain', 'url')
        ioc (str): The actual IOC value

        # Threat Assessment
        reputation_score (int | None): Reputation score if available (source-specific scale)
        malicious (bool | None): Whether the IOC is considered malicious
        confidence_score (int | None): Confidence level in the assessment (0-100)

        # Detection Statistics
        detection_stats (dict | None): Analysis results summary
            - malicious: count of engines flagging as malicious
            - suspicious: count of engines flagging as suspicious
            - harmless: count of engines flagging as harmless
            - undetected: count of engines with no verdict
            - total: total number of engines

        # Geolocation Data (for IPs)
        geo_info (dict | None):
            - country: country code
            - country_name: full country name
            - city: city name
            - region: region/state
            - coordinates: lat/long coordinates
            - timezone: timezone

        # Network/Infrastructure Info
        network_info (dict | None):
            - asn: autonomous system number
            - isp: internet service provider
            - organization: organization name
            - hostnames: list of associated hostnames
            - domain: associated domain

        # Abuse/Threat Indicators
        abuse_info (dict | None):
            - abuse_confidence_score: confidence in abuse (0-100)
            - total_reports: number of abuse reports
            - last_reported: timestamp of last report
            - is_tor: whether it's a Tor exit node
            - is_proxy: whether it's a proxy
            - is_whitelisted: whether it's whitelisted

        # Temporal Information
        timestamps (dict | None):
            - first_seen: first observation timestamp
            - last_seen: last observation timestamp
            - last_analysis: last analysis timestamp
            - last_modified: last modification timestamp

        # Tags and Categories
        tags (list[str]): List of tags/labels
        categories (list[str]): Categorizations (phishing, malware, etc.)

        # File-specific data (for file_hash IOCs)
        file_info (dict | None):
            - file_type: type of file
            - file_size: size in bytes
            - magic: file magic description
            - names: known file names
            - ssdeep: ssdeep fuzzy hash
            - md5: MD5 hash
            - sha1: SHA1 hash
            - sha256: SHA256 hash

        # Domain-specific data
        domain_info (dict | None):
            - registrar: domain registrar
            - creation_date: domain creation date
            - expiration_date: domain expiration date
            - whois_date: whois lookup date
            - nameservers: list of nameservers

        # Additional data
        additional_info (dict): Any other source-specific information
    """

    def __init__(
        self,
        source: str,
        ioc_type: str,
        ioc: str,
        reputation_score: int | None = None,
        malicious: bool | None = None,
        confidence_score: int | None = None,
        detection_stats: dict | None = None,
        geo_info: dict | None = None,
        network_info: dict | None = None,
        abuse_info: dict | None = None,
        timestamps: dict | None = None,
        tags: list[str] | None = None,
        categories: list[str] | None = None,
        file_info: dict | None = None,
        domain_info: dict | None = None,
        additional_info: dict | None = None,
    ):
        self.schema_version = "1.0"
        self.normalized_time = datetime.now(timezone.utc).isoformat()
        self.source = source
        self.ioc_type = ioc_type
        self.ioc = ioc
        self.reputation_score = reputation_score
        self.malicious = malicious
        self.confidence_score = confidence_score
        self.detection_stats = detection_stats
        self.geo_info = geo_info
        self.network_info = network_info
        self.abuse_info = abuse_info
        self.timestamps = timestamps
        self.tags = tags or []
        self.categories = categories or []
        self.file_info = file_info
        self.domain_info = domain_info
        self.additional_info = additional_info or {}


def normalize_ip_virustotal_data(raw_data: dict) -> ThreatIntelligenceNormalizedSchema:
    """Normalize VirusTotal IP data into the common schema.

    Args:
        raw_data (dict): Raw JSON data from VirusTotal for an IP.

    Returns:
        ThreatIntelligenceNormalizedSchema: Normalized threat intelligence data.
    """
    data = raw_data.get("data", {})
    attributes = data.get("attributes", {})

    # Extract IP address
    ioc = data.get("id", "")

    # Calculate detection stats from last_analysis_results
    last_analysis_results = attributes.get("last_analysis_results", {})
    detection_stats = {
        "malicious": 0,
        "suspicious": 0,
        "harmless": 0,
        "undetected": 0,
        "total": len(last_analysis_results),
    }

    for engine, result in last_analysis_results.items():
        category = result.get("category", "undetected")
        if category in detection_stats:
            detection_stats[category] += 1

    # Determine if malicious
    reputation = attributes.get("reputation")
    malicious = detection_stats["malicious"] > 0 or (
        reputation is not None and reputation < 0
    )

    # Extract network info
    network_info = {
        "asn": attributes.get("asn"),
        "organization": attributes.get("as_owner"),
    }

    # Extract geo info
    geo_info = {
        "country": attributes.get("country"),
        "continent": attributes.get("continent"),
    }

    # Extract timestamps
    timestamps = {
        "last_analysis": attributes.get("last_analysis_date"),
        "last_modified": attributes.get("last_modification_date"),
    }

    # Extract tags and categories
    tags = attributes.get("tags", [])
    categories = list(attributes.get("categories", {}).values())

    # Logging for debugging
    logger.debug(
        "Normalized VirusTotal IP data for IOC %s: malicious=%s, reputation=%s",
        ioc,
        malicious,
        reputation,
    )

    return ThreatIntelligenceNormalizedSchema(
        source="VirusTotal",
        ioc_type="ip",
        ioc=ioc,
        reputation_score=reputation,
        malicious=malicious,
        detection_stats=detection_stats,
        geo_info=geo_info,
        network_info=network_info,
        timestamps=timestamps,
        tags=tags,
        categories=categories,
    )


def normalize_file_hash_virustotal_data(
    raw_data: dict,
) -> ThreatIntelligenceNormalizedSchema:
    """Normalize VirusTotal file hash data into the common schema.

    Args:
        raw_data (dict): Raw JSON data from VirusTotal for a file hash.

    Returns:
        ThreatIntelligenceNormalizedSchema: Normalized threat intelligence data.
    """
    data = raw_data.get("data", {})
    attributes = data.get("attributes", {})

    # Extract file hash
    ioc = data.get("id", "")

    # Extract detection stats
    last_analysis_stats = attributes.get("last_analysis_stats", {})
    detection_stats = {
        "malicious": last_analysis_stats.get("malicious", 0),
        "suspicious": last_analysis_stats.get("suspicious", 0),
        "harmless": last_analysis_stats.get("harmless", 0),
        "undetected": last_analysis_stats.get("undetected", 0),
        "total": sum(last_analysis_stats.values()) if last_analysis_stats else 0,
    }

    # Determine if malicious
    malicious = detection_stats["malicious"] > 0
    reputation = attributes.get("reputation")

    # Calculate confidence score based on detection ratio
    confidence_score = None
    if detection_stats["total"] > 0:
        confidence_score = int(
            (detection_stats["malicious"] / detection_stats["total"]) * 100
        )

    # Extract file info
    known_distributors = attributes.get("known_distributors", {})
    file_info = {
        "file_type": attributes.get("type_description"),
        "file_size": attributes.get("size"),
        "magic": attributes.get("magic"),
        "names": known_distributors.get("filenames", []),
        "ssdeep": attributes.get("ssdeep"),
        "md5": attributes.get("md5"),
        "sha1": attributes.get("sha1"),
        "sha256": attributes.get("sha256"),
    }

    # Extract timestamps
    timestamps = {
        "first_seen": attributes.get("first_submission_date"),
        "last_seen": attributes.get("last_submission_date"),
        "last_analysis": attributes.get("last_analysis_date"),
        "last_modified": attributes.get("last_modification_date"),
    }

    # Extract tags and categories
    tags = attributes.get("tags", [])

    # Extract sandbox verdicts as categories
    sandbox_verdicts = attributes.get("sandbox_verdicts", {})
    categories = []
    for sandbox_name, verdict_info in sandbox_verdicts.items():
        if isinstance(verdict_info, dict):
            category = verdict_info.get("category")
            if category:
                categories.append(category)
            malware_classification = verdict_info.get("malware_classification", [])
            categories.extend(malware_classification)

    # Add distributors info to additional_info
    additional_info = {
        "times_submitted": attributes.get("times_submitted"),
        "unique_sources": attributes.get("unique_sources"),
        "known_distributors": known_distributors.get("distributors", []),
        "products": known_distributors.get("products", []),
    }

    # Logging for debugging
    logger.debug(
        "Normalized VirusTotal file hash data for IOC %s: malicious=%s, reputation=%s",
        ioc,
        malicious,
        reputation,
    )

    return ThreatIntelligenceNormalizedSchema(
        source="VirusTotal",
        ioc_type="file_hash",
        ioc=ioc,
        reputation_score=reputation,
        malicious=malicious,
        confidence_score=confidence_score,
        detection_stats=detection_stats,
        file_info=file_info,
        timestamps=timestamps,
        tags=tags,
        categories=categories,
        additional_info=additional_info,
    )


def normalize_domain_virustotal_data(
    raw_data: dict,
) -> ThreatIntelligenceNormalizedSchema:
    """Normalize VirusTotal domain data into the common schema.

    Args:
        raw_data (dict): Raw JSON data from VirusTotal for a domain.

    Returns:
        ThreatIntelligenceNormalizedSchema: Normalized threat intelligence data.
    """
    data = raw_data.get("data", {})
    attributes = data.get("attributes", {})

    # Extract domain
    ioc = data.get("id", "")

    # Calculate detection stats from last_analysis_results
    last_analysis_results = attributes.get("last_analysis_results", {})
    detection_stats = {
        "malicious": 0,
        "suspicious": 0,
        "harmless": 0,
        "undetected": 0,
        "total": len(last_analysis_results),
    }

    for engine, result in last_analysis_results.items():
        category = result.get("category", "undetected")
        if category in detection_stats:
            detection_stats[category] += 1

    # Determine if malicious
    reputation = attributes.get("reputation")
    malicious = detection_stats["malicious"] > 0 or (
        reputation is not None and reputation < 0
    )

    # Extract total votes for confidence
    total_votes = attributes.get("total_votes", {})
    harmless_votes = total_votes.get("harmless", 0)
    malicious_votes = total_votes.get("malicious", 0)
    total_vote_count = harmless_votes + malicious_votes

    confidence_score = None
    if total_vote_count > 0:
        confidence_score = int((malicious_votes / total_vote_count) * 100)

    # Extract domain info
    whois = attributes.get("whois", "")
    registrar = None
    if "Registrar:" in whois:
        for line in whois.split("\n"):
            if line.startswith("Registrar:"):
                registrar = line.split(":", 1)[1].strip()
                break

    # Extract creation date from whois
    creation_date = None
    if "Creation Date:" in whois:
        for line in whois.split("\n"):
            if line.startswith("Creation Date:"):
                creation_date = line.split(":", 1)[1].strip()
                break

    domain_info = {
        "registrar": registrar,
        "creation_date": creation_date,
        "expiration_date": attributes.get("expiration_date"),
        "whois_date": attributes.get("whois_date"),
        "tld": attributes.get("tld"),
    }

    # Extract timestamps
    timestamps = {
        "last_analysis": attributes.get("last_analysis_date"),
        "last_modified": attributes.get("last_update_date"),
    }

    # Extract tags and categories
    tags = attributes.get("tags", [])
    categories = list(attributes.get("categories", {}).values())

    # Extract popularity ranks
    popularity_ranks = attributes.get("popularity_ranks", {})
    additional_info = {
        "popularity_ranks": popularity_ranks,
        "total_votes": total_votes,
    }

    # Logging for debugging
    logger.debug(
        "Normalized VirusTotal domain data for IOC %s: malicious=%s, reputation=%s",
        ioc,
        malicious,
        reputation,
    )

    return ThreatIntelligenceNormalizedSchema(
        source="VirusTotal",
        ioc_type="domain",
        ioc=ioc,
        reputation_score=reputation,
        malicious=malicious,
        confidence_score=confidence_score,
        detection_stats=detection_stats,
        domain_info=domain_info,
        timestamps=timestamps,
        tags=tags,
        categories=categories,
        additional_info=additional_info,
    )


def normalize_abuseipdb_data(raw_data: dict) -> ThreatIntelligenceNormalizedSchema:
    """Normalize AbuseIPDB data into the common schema.

    Args:
        raw_data (dict): Raw JSON data from AbuseIPDB for an IP.

    Returns:
        ThreatIntelligenceNormalizedSchema: Normalized threat intelligence data.
    """
    data = raw_data.get("data", {})

    # Extract IP address
    ioc = data.get("ipAddress", "")

    # Get abuse confidence score
    abuse_confidence = data.get("abuseConfidenceScore", 0)

    # Determine if malicious (typically >50% confidence)
    malicious = abuse_confidence > 50

    # Build abuse info
    abuse_info = {
        "abuse_confidence_score": abuse_confidence,
        "total_reports": data.get("totalReports", 0),
        "last_reported": data.get("lastReportedAt"),
        "is_tor": data.get("isTor", False),
        "is_whitelisted": data.get("isWhitelisted", False),
        "num_distinct_users": data.get("numDistinctUsers", 0),
    }

    # Build geo info
    geo_info = {
        "country": data.get("countryCode"),
    }

    # Build network info
    network_info = {
        "isp": data.get("isp"),
        "domain": data.get("domain"),
        "hostnames": data.get("hostnames", []),
        "usage_type": data.get("usageType"),
    }

    # Additional info
    additional_info = {
        "is_public": data.get("isPublic"),
        "ip_version": data.get("ipVersion"),
    }

    # Logging for debugging
    logger.debug(
        "Normalized AbuseIPDB data for IOC %s: malicious=%s, abuse_confidence=%s",
        ioc,
        malicious,
        abuse_confidence,
    )

    return ThreatIntelligenceNormalizedSchema(
        source="AbuseIPDB",
        ioc_type="ip",
        ioc=ioc,
        malicious=malicious,
        confidence_score=abuse_confidence,
        geo_info=geo_info,
        network_info=network_info,
        abuse_info=abuse_info,
        additional_info=additional_info,
    )


def normalize_ipinfo_data(raw_data: dict) -> ThreatIntelligenceNormalizedSchema:
    """Normalize ipinfo.io data into the common schema.

    Args:
        raw_data (dict): Raw JSON data from ipinfo.io for an IP.

    Returns:
        ThreatIntelligenceNormalizedSchema: Normalized threat intelligence data.
    """
    # Extract IP address
    ioc = raw_data.get("ip", "")

    # Build geo info
    geo_info = {
        "country": raw_data.get("country"),
        "city": raw_data.get("city"),
        "region": raw_data.get("region"),
        "coordinates": raw_data.get("loc"),
        "timezone": raw_data.get("timezone"),
        "postal": raw_data.get("postal"),
    }

    # Build network info
    # Parse ASN from org field (format: "AS15169 Google LLC")
    org = raw_data.get("org", "")
    asn = None
    organization = org
    if org.startswith("AS"):
        parts = org.split(" ", 1)
        if len(parts) == 2:
            asn = parts[0]
            organization = parts[1]

    network_info = {
        "asn": asn,
        "organization": organization,
        "hostnames": [raw_data.get("hostname")] if raw_data.get("hostname") else [],
    }

    # Additional info
    additional_info = {
        "anycast": raw_data.get("anycast"),
    }

    # Logging for debugging
    logger.debug("Normalized ipinfo.io data for IOC %s", ioc)

    return ThreatIntelligenceNormalizedSchema(
        source="ipinfo.io",
        ioc_type="ip",
        ioc=ioc,
        geo_info=geo_info,
        network_info=network_info,
        additional_info=additional_info,
    )


def normalize_ip_alienvault_data(raw_data: dict) -> ThreatIntelligenceNormalizedSchema:
    """Normalize AlienVault OTX IP data into the common schema.

    Args:
        raw_data (dict): Raw JSON data from AlienVault OTX for an IP.

    Returns:
        ThreatIntelligenceNormalizedSchema: Normalized threat intelligence data.
    """
    # Extract IP address
    ioc = raw_data.get("indicator", "")

    # Extract reputation score
    reputation = raw_data.get("reputation", 0)

    # Extract pulse information
    pulse_info = raw_data.get("pulse_info", {})
    pulse_count = pulse_info.get("count", 0)
    pulses = pulse_info.get("pulses", [])

    # Determine if malicious based on reputation and pulse count
    # Negative reputation or multiple pulses may indicate malicious activity
    malicious = reputation < 0 or pulse_count > 0

    # Extract validation and false positive info
    validation = raw_data.get("validation", [])
    false_positive = raw_data.get("false_positive", [])

    # Check if whitelisted
    is_whitelisted = any(v.get("name") == "Whitelisted IP" for v in validation)

    # Extract tags and categories from pulses
    tags = []
    categories = []
    adversaries = []
    malware_families = []

    for pulse in pulses:
        pulse_tags = pulse.get("tags", [])
        tags.extend(pulse_tags)

        # Extract adversary info
        adversary = pulse.get("adversary", "")
        if adversary:
            adversaries.append(adversary)

        # Extract malware families
        malware = pulse.get("malware_families", [])
        if malware:
            for family in malware:
                if isinstance(family, dict):
                    malware_families.append(family.get("display_name", ""))
                else:
                    malware_families.append(str(family))

    # Deduplicate tags
    tags = list(set(tags))
    categories = list(set(malware_families))

    # Build geo info
    geo_info = {
        "country": raw_data.get("country_code"),
        "country_name": raw_data.get("country_name"),
        "city": raw_data.get("city"),
        "region": raw_data.get("region"),
        "coordinates": (
            f"{raw_data.get('latitude')},{raw_data.get('longitude')}"
            if raw_data.get("latitude")
            else None
        ),
        "continent_code": raw_data.get("continent_code"),
    }

    # Build network info
    asn_info = raw_data.get("asn", "")
    network_info = {
        "asn": asn_info.split()[0] if asn_info else None,
        "organization": " ".join(asn_info.split()[1:]) if asn_info else None,
    }

    # Build abuse info
    abuse_info = {
        "is_whitelisted": is_whitelisted,
        "pulse_count": pulse_count,
        "false_positive_count": len(false_positive),
    }

    # Calculate confidence score based on pulse count and validation
    confidence_score = None
    if pulse_count > 0:
        # Higher pulse count = higher confidence in malicious verdict
        confidence_score = min(pulse_count * 10, 100)  # Cap at 100

    # Reduce confidence if whitelisted or false positives exist
    if is_whitelisted:
        confidence_score = 0
        malicious = False
    elif len(false_positive) > 0:
        confidence_score = max(0, (confidence_score or 0) - len(false_positive) * 10)

    # Additional info
    additional_info = {
        "whois_link": raw_data.get("whois"),
        "sections": raw_data.get("sections", []),
        "validation": validation,
        "false_positive": false_positive,
        "adversaries": list(set(adversaries)),
    }

    # Logging for debugging
    logger.debug(
        "Normalized AlienVault IP data for IOC %s: malicious=%s, reputation=%s, pulse_count=%s",
        ioc,
        malicious,
        reputation,
        pulse_count,
    )

    return ThreatIntelligenceNormalizedSchema(
        source="AlienVault OTX",
        ioc_type="ip",
        ioc=ioc,
        reputation_score=reputation,
        malicious=malicious,
        confidence_score=confidence_score,
        geo_info=geo_info,
        network_info=network_info,
        abuse_info=abuse_info,
        tags=tags,
        categories=categories,
        additional_info=additional_info,
    )


def normalize_domain_alienvault_data(
    raw_data: dict,
) -> ThreatIntelligenceNormalizedSchema:
    """Normalize AlienVault OTX domain data into the common schema.

    Args:
        raw_data (dict): Raw JSON data from AlienVault OTX for a domain.

    Returns:
        ThreatIntelligenceNormalizedSchema: Normalized threat intelligence data.
    """
    # Extract domain
    ioc = raw_data.get("indicator", "")

    # Extract pulse information
    pulse_info = raw_data.get("pulse_info", {})
    pulse_count = pulse_info.get("count", 0)
    pulses = pulse_info.get("pulses", [])

    # Extract validation and false positive info
    validation = raw_data.get("validation", [])
    false_positive = raw_data.get("false_positive", [])

    # Check if whitelisted
    is_whitelisted = any("Whitelisted domain" in v.get("name", "") for v in validation)

    # Determine if malicious based on pulse count and validation
    malicious = pulse_count > 0 and not is_whitelisted

    # Extract tags and categories from pulses
    tags = []
    categories = []
    adversaries = []
    malware_families = []

    for pulse in pulses:
        pulse_tags = pulse.get("tags", [])
        tags.extend(pulse_tags)

        # Extract adversary info
        adversary = pulse.get("adversary", "")
        if adversary:
            adversaries.append(adversary)

        # Extract malware families
        malware = pulse.get("malware_families", [])
        if malware:
            for family in malware:
                if isinstance(family, dict):
                    malware_families.append(family.get("display_name", ""))
                else:
                    malware_families.append(str(family))

    # Deduplicate tags and categories
    tags = list(set(tags))
    categories = list(set(malware_families))

    # Calculate confidence score based on pulse count and validation
    confidence_score = None
    if pulse_count > 0:
        # Higher pulse count = higher confidence
        confidence_score = min(pulse_count * 5, 100)  # Cap at 100

    # Adjust confidence based on validation
    if is_whitelisted:
        confidence_score = 0
        malicious = False
    elif len(false_positive) > 0:
        confidence_score = max(0, (confidence_score or 0) - len(false_positive) * 10)

    # Extract Alexa rank from validation if available
    alexa_rank = None
    akamai_rank = None
    for v in validation:
        if "Akamai" in v.get("name", ""):
            message = v.get("message", "")
            # Parse "Akamai rank: #1458"
            if "#" in message:
                try:
                    akamai_rank = int(message.split("#")[1])
                except (ValueError, IndexError):
                    pass
        elif "Alexa" in v.get("name", ""):
            message = v.get("message", "")
            if "#" in message:
                try:
                    alexa_rank = int(message.split("#")[1])
                except (ValueError, IndexError):
                    pass

    # Build domain info
    domain_info = {
        "alexa_rank": alexa_rank,
        "akamai_rank": akamai_rank,
    }

    # Build abuse info
    abuse_info = {
        "is_whitelisted": is_whitelisted,
        "pulse_count": pulse_count,
        "false_positive_count": len(false_positive),
    }

    # Additional info
    additional_info = {
        "whois_link": raw_data.get("whois"),
        "alexa_link": raw_data.get("alexa"),
        "sections": raw_data.get("sections", []),
        "validation": validation,
        "false_positive": false_positive,
        "adversaries": list(set(adversaries)),
    }

    # Logging for debugging
    logger.debug(
        "Normalized AlienVault domain data for IOC %s: malicious=%s, pulse_count=%s, whitelisted=%s",
        ioc,
        malicious,
        pulse_count,
        is_whitelisted,
    )

    return ThreatIntelligenceNormalizedSchema(
        source="AlienVault OTX",
        ioc_type="domain",
        ioc=ioc,
        malicious=malicious,
        confidence_score=confidence_score,
        domain_info=domain_info,
        abuse_info=abuse_info,
        tags=tags,
        categories=categories,
        additional_info=additional_info,
    )


def normalize_urlscan_data(raw_data: dict) -> ThreatIntelligenceNormalizedSchema:
    """Normalize URLScan.io data into the common schema.

    Args:
        raw_data (dict): Raw JSON data from URLScan.io for a URL scan.

    Returns:
        ThreatIntelligenceNormalizedSchema: Normalized threat intelligence data.
    """
    # Extract task information
    task = raw_data.get("task", {})
    ioc = task.get("url", "")

    # Extract page information
    page = raw_data.get("page", {})

    # Extract verdicts
    verdicts = raw_data.get("verdicts", {})
    overall_verdict = verdicts.get("overall", {})
    urlscan_verdict = verdicts.get("urlscan", {})
    engines_verdict = verdicts.get("engines", {})
    community_verdict = verdicts.get("community", {})

    # Determine if malicious
    malicious = overall_verdict.get("malicious", False)

    # Get confidence score from overall verdict
    # URLScan scores range from -100 to 100, normalize to 0-100
    overall_score = overall_verdict.get("score", 0)
    if overall_score < 0:
        confidence_score = 0
    else:
        confidence_score = min(overall_score, 100)

    # Build detection stats from engines verdict
    detection_stats = None
    if engines_verdict.get("hasVerdicts"):
        detection_stats = {
            "malicious": engines_verdict.get("maliciousTotal", 0),
            "suspicious": 0,  # URLScan doesn't have this category
            "harmless": engines_verdict.get("benignTotal", 0),
            "undetected": 0,
            "total": engines_verdict.get("enginesTotal", 0),
        }

    # Extract geo info from page
    geo_info = {
        "country": page.get("country"),
        "city": page.get("city"),
    }

    # Extract network info
    network_info = {
        "asn": page.get("asn"),
        "organization": page.get("asnname"),
        "domain": page.get("domain"),
    }

    # Extract domain info
    domain_info = None
    apex_domain = page.get("apexDomain")
    if apex_domain:
        domain_info = {
            "apex_domain": apex_domain,
            "domain_age_days": page.get("domainAgeDays"),
            "apex_domain_age_days": page.get("apexDomainAgeDays"),
            "tls_issuer": page.get("tlsIssuer"),
            "tls_valid_days": page.get("tlsValidDays"),
            "tls_age_days": page.get("tlsAgeDays"),
            "tls_valid_from": page.get("tlsValidFrom"),
        }

    # Extract timestamps
    timestamps = {
        "scan_time": task.get("time"),
    }

    # Combine tags from overall verdict and task
    tags = []
    tags.extend(overall_verdict.get("tags", []))
    tags.extend(task.get("tags", []))
    tags.extend(engines_verdict.get("tags", []))
    tags = list(set(tags))  # Deduplicate

    # Extract categories from verdicts
    categories = []
    categories.extend(overall_verdict.get("categories", []))
    categories.extend(urlscan_verdict.get("categories", []))
    categories.extend(engines_verdict.get("categories", []))
    categories = list(set(categories))  # Deduplicate

    # Extract brands
    brands = []
    brands.extend(overall_verdict.get("brands", []))
    brands.extend(urlscan_verdict.get("brands", []))
    brands = list(set(brands))  # Deduplicate

    # Extract lists
    lists = raw_data.get("lists", {})

    # Extract stats
    stats = raw_data.get("stats", {})

    # Build additional info
    additional_info = {
        "scan_uuid": task.get("uuid"),
        "report_url": task.get("reportURL"),
        "screenshot_url": task.get("screenshotURL"),
        "dom_url": task.get("domURL"),
        "visibility": task.get("visibility"),
        "submitter_country": raw_data.get("submitter", {}).get("country"),
        "scanner_country": raw_data.get("scanner", {}).get("country"),
        "page_ip": page.get("ip"),
        "page_status": page.get("status"),
        "page_title": page.get("title"),
        "page_server": page.get("server"),
        "page_mime_type": page.get("mimeType"),
        "page_language": page.get("language"),
        "umbrella_rank": page.get("umbrellaRank"),
        "redirected": page.get("redirected"),
        "brands": brands,
        "associated_ips": lists.get("ips", []),
        "associated_domains": lists.get("domains", []),
        "associated_urls": lists.get("urls", []),
        "link_domains": lists.get("linkDomains", []),
        "certificates": lists.get("certificates", []),
        "hashes": lists.get("hashes", []),
        "malicious_count": stats.get("malicious", 0),
        "total_links": stats.get("totalLinks", 0),
        "ad_blocked": stats.get("adBlocked", 0),
        "secure_percentage": stats.get("securePercentage", 0),
        "community_votes": {
            "total": community_verdict.get("votesTotal", 0),
            "malicious": community_verdict.get("votesMalicious", 0),
            "benign": community_verdict.get("votesBenign", 0),
        },
        "engines_verdicts": {
            "malicious": engines_verdict.get("maliciousVerdicts", []),
            "benign": engines_verdict.get("benignVerdicts", []),
        },
    }

    # Logging for debugging
    logger.debug(
        "Normalized URLScan data for IOC %s: malicious=%s, score=%s, engines_total=%s",
        ioc,
        malicious,
        overall_score,
        engines_verdict.get("enginesTotal", 0),
    )

    return ThreatIntelligenceNormalizedSchema(
        source="URLScan.io",
        ioc_type="url",
        ioc=ioc,
        malicious=malicious,
        confidence_score=confidence_score,
        detection_stats=detection_stats,
        geo_info=geo_info,
        network_info=network_info,
        domain_info=domain_info,
        timestamps=timestamps,
        tags=tags,
        categories=categories,
        additional_info=additional_info,
    )
